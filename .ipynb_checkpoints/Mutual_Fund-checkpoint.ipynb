{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "40e2452a-821e-46b7-bf6e-b9019fbbf750",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "25db0363-a801-4780-b208-9a48fd6d5f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mutual_fund_categories_amfi():\n",
    "    df_mf_list = pd.read_csv('https://portal.amfiindia.com/DownloadSchemeData_Po.aspx?mf=0', header = 'infer')\n",
    "    df_mf_list.columns = df_mf_list.columns.str.strip()\n",
    "    df_mf_list.replace(np.nan,'', inplace = True)\n",
    "    scheme_categories = df_mf_list['Scheme Category'].unique() ### use df_mf_list_1 after remove the category condition to get this\n",
    "    # df_mf_list_1 = df_mf_list[(df_mf_list['Closure Date'] == '') & (df_mf_list['Scheme Category'] == 'Equity Scheme - Flexi Cap Fund') & (df_mf_list['Scheme NAV Name'].str.contains(\"Direct\") == True) & (df_mf_list['Scheme NAV Name'].str.contains(\"Growth\") == True)].reset_index(drop=True)\n",
    "    df_mf_list_1 = df_mf_list[(df_mf_list['Scheme Category'] == 'Equity Scheme - Flexi Cap Fund') & (df_mf_list['Scheme NAV Name'].str.contains(\"direct\", case=False)) & (df_mf_list['Scheme NAV Name'].str.contains(\"growth\", case=False))].reset_index(drop=True)\n",
    "    return df_mf_list_1\n",
    "\n",
    "def get_mf_price_data_mfapi(code, ):\n",
    "    mf_data_response = requests.get(f\"https://api.mfapi.in/mf/{code}\", allow_redirects = True)\n",
    "    mf_data_1 = json.loads(mf_data_response.content.decode('utf-8'))\n",
    "    # mf_data = pd.json_normalize(mf_data_1['data'])\n",
    "    mf_data = pd.json_normalize(mf_data_1)\n",
    "    mf_data_df = pd.DataFrame.from_dict(mf_data['data'][0])\n",
    "    mf_data_df['date'] = pd.to_datetime(mf_data_df['date'], format = '%d-%m-%Y')\n",
    "    mf_data_df['nav'] = mf_data_df['nav'].astype(float)\n",
    "    mf_data_df = mf_data_df.sort_values('date')\n",
    "    mf_data_df['daily_returns'] = mf_data_df['nav'].pct_change()\n",
    "    mf_data_df['cumulative_returns'] = (mf_data_df['daily_returns']+1).cumprod()\n",
    "    return mf_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9bf87b6e-6a0e-470f-9b35-b114a0c4f861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mutual_fund_list_mfapi():\n",
    "    response = requests.get(\"https://api.mfapi.in/mf\", allow_redirects = True)\n",
    "    data = json.loads(response.content.decode('utf-8'))\n",
    "    df_mf_list = pd.json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c115c932-0965-43de-add5-fd27921e4de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_return_by_timeframe(returns_df, df, no_of_years):\n",
    "    cutoff = datetime.datetime.now() - datetime.timedelta(days=no_of_years*365)\n",
    "    filtered_schemes = df.groupby('Scheme Code')['date'].min()\n",
    "    filtered_schemes = filtered_schemes[filtered_schemes <= cutoff].index\n",
    "    filtered_df = df[df['Scheme Code'].isin(filtered_schemes)]\n",
    "\n",
    "    col_name_total = f'{no_of_years}Y Return'\n",
    "    col_name_cagr = f'{no_of_years}Y CAGR %'\n",
    "    \n",
    "    data = {\n",
    "        'scheme_code': [],\n",
    "        'scheme_name': [],\n",
    "        col_name_total: [],\n",
    "        col_name_cagr: []\n",
    "    }\n",
    "    \n",
    "    returns = []\n",
    "\n",
    "    for scheme, group in filtered_df.groupby('Scheme Code'):\n",
    "        if df.groupby('Scheme Code')['date'].min()>=cutoff:\n",
    "            data['scheme_code'].append(scheme)\n",
    "            data['scheme_name'].append(group_sorted.iloc[0]['Scheme Name'])\n",
    "            data[col_name_total].append(0)\n",
    "            data[col_name_cagr].append(0)\n",
    "        else:\n",
    "            group_sorted = group.sort_values('date')\n",
    "            start_val = group_sorted.loc[group_sorted['date']>= cutoff].iloc[0]['nav']\n",
    "            end_val = group_sorted.iloc[-1]['nav']\n",
    "            total_return = (end_val / start_val - 1) * 100\n",
    "            cagr = ((1 + total_return / 100) ** (1 / no_of_years) - 1) * 100\n",
    "            data['scheme_code'].append(scheme)\n",
    "            data['scheme_name'].append(group_sorted.iloc[0]['Scheme Name'])\n",
    "            data[col_name_total].append(total_return)\n",
    "            data[col_name_cagr].append(cagr)\n",
    "            # returns.append((scheme, group_sorted.iloc[0]['Scheme Name'], total_return, cagr))\n",
    "\n",
    "    # Now add all at once\n",
    "    for col, values in data.items():\n",
    "        returns_df[col] = values\n",
    "    return returns_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "de0c17c0-ac55-4577-9f4a-686eb1b9eb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file already exist\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (23) does not match length of index (29)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[125], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m returns_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[0;32m     22\u001b[0m returns_df \u001b[38;5;241m=\u001b[39m calculate_return_by_timeframe(returns_df, final_df, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 23\u001b[0m returns_df \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_return_by_timeframe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturns_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[124], line 33\u001b[0m, in \u001b[0;36mcalculate_return_by_timeframe\u001b[1;34m(returns_df, df, no_of_years)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;66;03m# returns.append((scheme, group_sorted.iloc[0]['Scheme Name'], total_return, cagr))\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Now add all at once\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m col, values \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m---> 33\u001b[0m     \u001b[43mreturns_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m values\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m returns_df\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (23) does not match length of index (29)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    all_funds = []\n",
    "    mutual_fund_list = read_mutual_fund_categories_amfi()\n",
    "    if os.path.exists('mf_data.csv'):\n",
    "    # if 1 == 2:\n",
    "        print('file already exist')\n",
    "        final_df = pd.read_csv(\"mf_data.csv\")\n",
    "    else:\n",
    "        for index, row in mutual_fund_list.iterrows():\n",
    "            code = row['Code']\n",
    "            mf_data_df = get_mf_price_data_mfapi(code)\n",
    "            mf_data_df['Scheme Code'] = row['Code']\n",
    "            mf_data_df['Scheme Name'] = row['Scheme Name']\n",
    "            mf_data_df['Scheme Category'] = row['Scheme Category']\n",
    "            all_funds.append(mf_data_df)\n",
    "            print(f\"{code} - {row['Scheme Name']}\")\n",
    "        final_df = pd.concat(all_funds, ignore_index=True)\n",
    "        final_df = final_df[['Scheme Code', 'Scheme Name', 'Scheme Category', 'date', 'nav' , 'daily_returns', 'cumulative_returns']]\n",
    "        final_df.to_csv(\"mf_data.csv\")\n",
    "    final_df['date'] = pd.to_datetime(final_df['date'])\n",
    "    returns_df = pd.DataFrame()\n",
    "    returns_df = calculate_return_by_timeframe(returns_df, final_df, 3)\n",
    "    returns_df = calculate_return_by_timeframe(returns_df, final_df, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437175c2-9fac-402d-80f1-4aa015137a6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
